{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrachurh\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\chandrachurh\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\chandrachurh\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from scipy import ndimage\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as s_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop, Adam\n",
    "from keras.layers import Conv2D , SeparableConv2D, BatchNormalization, UpSampling2D, MaxPool2D\n",
    "from keras.layers import MaxPooling2D, Average, Input, Concatenate, LeakyReLU, Add, ELU, PReLU, ReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as BE\n",
    "from vis.visualization import visualize_cam, visualize_cam_with_losses, visualize_activation, visualize_saliency\n",
    "from vis.utils import utils\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>The data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def set_data(path):\n",
    "    for next_dir in os.listdir(path):\n",
    "        temp = path + next_dir\n",
    "        for dirc in os.listdir(temp):\n",
    "            temp1 = path +next_dir+'/'+dirc\n",
    "            for file in tqdm(os.listdir(temp1)):\n",
    "                img = cv2.imread(temp1+\"/\"+file)\n",
    "                img = cv2.resize(img, (50,50))\n",
    "                if dirc ==\"0\":\n",
    "                    cv2.imwrite(\"data/NORMAL/\"+file,img)\n",
    "                else:\n",
    "                    cv2.imwrite(\"data/IDC/\"+file,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "set_data(\"kaggle_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>The Model Development</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(path):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for nextDir in os.listdir(path):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['IDC']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "\n",
    "            temp = path + nextDir\n",
    "\n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file, 1)\n",
    "                img = cv2.resize(img,(100,100))\n",
    "                img1 = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2LAB))[0]\n",
    "                img2 = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))[0]\n",
    "                img3 = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))[1]\n",
    "                img4 = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2LAB))[1]\n",
    "                if img is not None:\n",
    "                    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(16,16))\n",
    "                    planes = cv2.split(img)\n",
    "                    for i in range(0,3):\n",
    "                        planes[i] =clahe.apply(planes[i])\n",
    "                    img = cv2.merge(planes)\n",
    "                    #img = clahe.apply(img)\n",
    "                    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "                    #img = skimage.transform.resize(img, (299, 299, 3))\n",
    "                    img = cv2.merge([img,img1,img2,img3,img4])\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:18<00:00, 165.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4500/4500 [00:27<00:00, 165.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = get_image_data(\"fur_fur_fur_reduced_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X_shu, y_shu):\n",
    "    #X_shu=np.asarray(X_shu)\n",
    "    #y_shu=np.asarray(y_shu)\n",
    "    split = s_split(n_splits= 1, test_size = 0.15, random_state=18)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for train_id, test_id in split.split(X_shu, y_shu):\n",
    "        X_train.append(X_shu[train_id])\n",
    "        y_train.append(y_shu[train_id])\n",
    "        X_test.append(X_shu[test_id])\n",
    "        y_test.append(y_shu[test_id])\n",
    "    #del X_shu\n",
    "    #del y_shu\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = shuffle_data(X,y)\n",
    "X_train = np.asarray(X_train, dtype = \"float32\")[0]\n",
    "X_test = np.asarray(X_test, dtype = \"float32\")[0]\n",
    "y_train = np.asarray(y_train)[0]\n",
    "y_test = np.asarray(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test,2)\n",
    "y_train = to_categorical(y_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 100, 100, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>The Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(mod_, f_in, f_out, strides_ = (1,1), use_shortcut_ = False):   \n",
    "    shortcut_ = mod_\n",
    "    \n",
    "    k_ = (1,1)\n",
    "    \n",
    "    mod_ = Conv2D(f_in, kernel_size=k_, strides=(1,1), padding = \"same\")(mod_)\n",
    "    mod_ = BatchNormalization()(mod_)\n",
    "    mod_ = ELU()(mod_)\n",
    "    \n",
    "    mod_ = Conv2D(f_in, kernel_size=k_, strides=strides_, padding = \"same\")(mod_)\n",
    "    mod_ = BatchNormalization()(mod_)\n",
    "    mod_ = ELU()(mod_)\n",
    "    \n",
    "    mod_ = Conv2D(f_out, kernel_size=k_, strides=(1,1), padding = \"same\")(mod_)\n",
    "    mod_ = BatchNormalization()(mod_)\n",
    "    mod_ = ELU()(mod_)\n",
    "    \n",
    "    if use_shortcut_ == True or strides_ != (1,1):\n",
    "        shortcut_ = Conv2D(f_out, kernel_size=k_, strides=strides_, padding = \"same\")(shortcut_)\n",
    "        shortcut_ = BatchNormalization()(shortcut_)\n",
    "        \n",
    "    mod_ = Add()([shortcut_, mod_])\n",
    "    mod_ = ReLU()(mod_)\n",
    "    \n",
    "    return mod_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(in_):\n",
    "    \n",
    "    k_=(1,1)\n",
    "    \n",
    "    mod_ = Conv2D(16, kernel_size=k_, strides = (1,1), padding = \"same\")(in_)\n",
    "    \n",
    "    mod_ = BatchNormalization()(mod_)\n",
    "    \n",
    "    mod_ = ReLU()(mod_)\n",
    "    \n",
    "    mod_ = MaxPooling2D()(mod_)\n",
    "    \n",
    "    mod_ = residual_block(mod_, 16, 32, use_shortcut_=True)\n",
    "    \n",
    "    mod_ = MaxPooling2D()(mod_)\n",
    "    \n",
    "    mod_ = residual_block(mod_, 32, 64, use_shortcut_=True)\n",
    "    \n",
    "    mod_ = MaxPooling2D()(mod_)\n",
    "    \n",
    "    mod_ = residual_block(mod_, 64, 96, use_shortcut_=True)\n",
    "    \n",
    "    mod_ = MaxPooling2D()(mod_)\n",
    "    \n",
    "    mod_ = residual_block(mod_, 96, 128, use_shortcut_=True)\n",
    "    \n",
    "    mod_ = MaxPooling2D()(mod_)\n",
    "    \n",
    "    mod_ = GlobalAveragePooling2D()(mod_)\n",
    "    \n",
    "    mod_ = Dense(512, activation = \"relu\")(mod_)\n",
    "    \n",
    "    mod_ = Dropout(0.5)(mod_)\n",
    "    \n",
    "    mod_ = Dense(2, activation=\"softmax\")(mod_)\n",
    "    \n",
    "    return mod_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ = Input((100,100,7))\n",
    "model = model_build(in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrachurh\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_f = Model(input = in_, output = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 100, 7)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 100, 16) 128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100, 100, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 100, 100, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 16)   0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 50, 50, 16)   272         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 50, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 50, 50, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 50, 50, 16)   272         elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 50, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_2 (ELU)                     (None, 50, 50, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 50, 50, 32)   544         elu_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 50, 50, 32)   544         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 50, 50, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 50, 50, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_3 (ELU)                     (None, 50, 50, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 50, 32)   0           batch_normalization_5[0][0]      \n",
      "                                                                 elu_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 50, 50, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 32)   0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 32)   1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_4 (ELU)                     (None, 25, 25, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 32)   1056        elu_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_5 (ELU)                     (None, 25, 25, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   2112        elu_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   2112        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_6 (ELU)                     (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 elu_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 25, 25, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 64)   0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 12, 64)   4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 12, 12, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_7 (ELU)                     (None, 12, 12, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 12, 64)   4160        elu_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 12, 12, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_8 (ELU)                     (None, 12, 12, 64)   0           batch_normalization_11[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 96)   6240        elu_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 96)   6240        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 12, 12, 96)   384         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 12, 12, 96)   384         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_9 (ELU)                     (None, 12, 12, 96)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 12, 12, 96)   0           batch_normalization_13[0][0]     \n",
      "                                                                 elu_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 12, 12, 96)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 96)     0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 6, 6, 96)     9312        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6, 6, 96)     384         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_10 (ELU)                    (None, 6, 6, 96)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 6, 6, 96)     9312        elu_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 6, 6, 96)     384         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_11 (ELU)                    (None, 6, 6, 96)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 6, 6, 128)    12416       elu_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 6, 6, 128)    12416       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 6, 6, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 6, 6, 128)    512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elu_12 (ELU)                    (None, 6, 6, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 128)    0           batch_normalization_17[0][0]     \n",
      "                                                                 elu_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 6, 6, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 128)    0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          66048       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            1026        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 143,714\n",
      "Trainable params: 141,570\n",
      "Non-trainable params: 2,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_f.compile(optimizer = RMSprop(), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_f.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Specifying parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 50\n",
    "nb_batch = 20\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=2, verbose=1)\n",
    "\n",
    "save_path=\"weights/res5_7x7_BGR_l_h_s_a_clahe_20_blur_new_fur_fur_fur_reddata_ELU_acti_convo_test_lastelu.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=model_f.fit(X_train, y_train, epochs = nb_epochs, batch_size = nb_batch, callbacks=[earlyStopping, lr_reduce, checkpoint], validation_data=(X_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/res4_1x1_BGR_l_h_s_a_clahe_20_blur_new_fur_fur_fur_reddata_ELU_acti_convo_test_lastelu', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_f.load_weights(\"weights/res4_1x1_BGR_l_h_s_a_clahe_20_blur_new_fur_fur_fur_reddata_ELU_acti_convo_test_lastelu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022613801583406208, 0.9937777777777778]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f.evaluate(X_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font  size=5>Visualization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=13\n",
    "plt.imshow(cv2.merge(cv2.split(X_test[idx])[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(X_test[idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_f.predict(x, verbose=1)[0].argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visualize_cam(model=model_f, layer_idx=utils.find_layer_idx(model_f, 're_lu_4'), filter_indices=None, seed_input=np.asarray(X_test[idx]), penultimate_layer_idx=utils.find_layer_idx(model_f, 'add_3'), \\\n",
    "    backprop_modifier=None, grad_modifier=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =  5>The performance metrics</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels = np.argmax(y_test, axis = 1)\n",
    "y_test_pred_incep = np.argmax(model_f.predict(X_test),axis = 1)\n",
    "print(precision_score(y_test_labels, y_test_pred_incep))\n",
    "print(recall_score(y_test_labels, y_test_pred_incep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_probs = model_f.predict([X_test])\n",
    "fpr, tpr, thresholds = roc_curve(y_test_labels, y_pred_probs[:, 1])\n",
    "def plot_roc_curve(fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label = label)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.xlabel(\"True Positive Rate\")\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()\n",
    "roc_auc_score(y_test_labels,y_pred_probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = open('history/res3_3x3_BGR_l_h_s_a_clahe_24_blur_new_fur_fur_reddata_acti',\"rb\")\n",
    "history = pickle.load(filename)\n",
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
